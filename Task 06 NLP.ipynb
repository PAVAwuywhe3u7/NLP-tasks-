{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNGHc8/BKRApCWJe2vl3wtb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_3GBS8leSnY","executionInfo":{"status":"ok","timestamp":1754888805780,"user_tz":-330,"elapsed":18165,"user":{"displayName":"TUMMEPALLI PAVANKARTHIK,CSE(2022) Vel Tech, Chennai","userId":"12502267669211204278"}},"outputId":"abc0b9c4-4cdd-4a39-e8d1-d3ddc159e135"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter a sentence: The quick brown fox jumps over the lazy dog\n","Enter the value of N for N-grams: 3\n","Next words: </s> </s> </s>\n"]}],"source":["import nltk\n","from nltk.util import ngrams\n","from nltk.lm import Laplace\n","from nltk.tokenize import word_tokenize\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","\n","def ngram_smoothing(sentence, n):\n","    tokens = word_tokenize(sentence.lower())\n","    # We wrap tokens in a list to indicate a single sentence\n","    train_data, padded_sents = padded_everygram_pipeline(n, [tokens])\n","\n","    model = Laplace(n)\n","    model.fit(train_data, padded_sents)\n","    return model\n","\n","\n","sentence = input(\"Enter a sentence: \")\n","n = int(input(\"Enter the value of N for N-grams: \"))\n","\n","model = ngram_smoothing(sentence, n)\n","\n","\n","if n > 1:\n","    context = tuple(sentence.lower().split()[-(n-1):])\n","else:\n","    context = ()\n","\n","next_words = model.generate(3, text_seed=context)\n","print(\"Next words:\", ' '.join(next_words))"]}]}